{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h1 id=\"웹-크롤링1---Static-Crawling\">웹 크롤링1 - Static Crawling<a class=\"anchor-link\" href=\"https://eclass2.ajou.ac.kr/bbcswebdav/pid-677816-dt-content-rid-9690516_1/courses/2020U00020032020084481/Crawling_exercise1.html#%EC%9B%B9-%ED%81%AC%EB%A1%A4%EB%A7%811---Static-Crawling\">¶</a></h1>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<hr/>\n",
    "<h1 id=\"1.-urllib\">1. <code>urllib</code><a class=\"anchor-link\" href=\"https://eclass2.ajou.ac.kr/bbcswebdav/pid-677816-dt-content-rid-9690516_1/courses/2020U00020032020084481/Crawling_exercise1.html#1.-urllib\">¶</a></h1><ul>\n",
    "<li>파이썬은 웹 사이트에 있는 데이터를 추출하기 위해 <code>urllib</code> 라이브러리 사용</li>\n",
    "<li>이를 이용해 HTTP 또는 FTP를 사용해 데이터 다운로드 가능</li>\n",
    "<li><code>urllib</code>은 URL을 다루는 모듈을 모아 놓은 패키지</li>\n",
    "<li><code>urllib.request</code> 모듈은 웹 사이트에 있는 데이터에 접근하는 기능 제공, 또한 인증, 리다렉트, 쿠키처럼 인터넷을 이용한 다양한 요청과 처리가 가능</li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from urllib import request\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h2 id=\"1.1.-urllib.request를-이용한-다운로드\">1.1. <code>urllib.request</code>를 이용한 다운로드<a class=\"anchor-link\" href=\"https://eclass2.ajou.ac.kr/bbcswebdav/pid-677816-dt-content-rid-9690516_1/courses/2020U00020032020084481/Crawling_exercise1.html#1.1.-urllib.request%EB%A5%BC-%EC%9D%B4%EC%9A%A9%ED%95%9C-%EB%8B%A4%EC%9A%B4%EB%A1%9C%EB%93%9C\">¶</a></h2><ul>\n",
    "<li>urllib.request 모듈에 있는 urlretrieve() 함수 이용</li>\n",
    "<li>다음의 코드는 PNG 파일을 test.png 라는 이름의 파일로 저장하는 예제임</li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 라이브러리 읽어들이기 \n",
    "from urllib import request\n",
    "\n",
    "url=\"http://uta.pw/shodou/img/28/214.png\"\n",
    "savename=\"test.png\"\n",
    "\n",
    "request.urlretrieve(url, savename)\n",
    "print(\"저장되었습니다\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h2 id=\"1.2.-urlopen으로-파일에-저장하는-방법\">1.2. urlopen으로 파일에 저장하는 방법<a class=\"anchor-link\" href=\"https://eclass2.ajou.ac.kr/bbcswebdav/pid-677816-dt-content-rid-9690516_1/courses/2020U00020032020084481/Crawling_exercise1.html#1.2.-urlopen%EC%9C%BC%EB%A1%9C-%ED%8C%8C%EC%9D%BC%EC%97%90-%EC%A0%80%EC%9E%A5%ED%95%98%EB%8A%94-%EB%B0%A9%EB%B2%95\">¶</a></h2><ul>\n",
    "<li>request.urlopen()은 메모리에 데이터를 올린 후 파일에 저장하게 된다.</li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# URL과 저장경로 지정하기\n",
    "url = \"http://uta.pw/shodou/img/28/214.png\"\n",
    "savename = \"test1.png\"\n",
    "#다운로드\n",
    "mem = request.urlopen(url).read()\n",
    "#파일로 저장하기, wb는 쓰기와 바이너리모드\n",
    "with open(savename, mode=\"wb\") as f:\n",
    "    f.write(mem)\n",
    "    print(\"저장되었습니다..\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h2 id=\"1.3.-API-사용하기\">1.3. API 사용하기<a class=\"anchor-link\" href=\"https://eclass2.ajou.ac.kr/bbcswebdav/pid-677816-dt-content-rid-9690516_1/courses/2020U00020032020084481/Crawling_exercise1.html#1.3.-API-%EC%82%AC%EC%9A%A9%ED%95%98%EA%B8%B0\">¶</a></h2><h3 id=\"클라이언트-접속-정보-출력-(기본)\">클라이언트 접속 정보 출력 (기본)<a class=\"anchor-link\" href=\"https://eclass2.ajou.ac.kr/bbcswebdav/pid-677816-dt-content-rid-9690516_1/courses/2020U00020032020084481/Crawling_exercise1.html#%ED%81%B4%EB%9D%BC%EC%9D%B4%EC%96%B8%ED%8A%B8-%EC%A0%91%EC%86%8D-%EC%A0%95%EB%B3%B4-%EC%B6%9C%EB%A0%A5-(%EA%B8%B0%EB%B3%B8)\">¶</a></h3><ul>\n",
    "<li>API는 사용자의 요청에 따라 정보를 반환하는 프로그램</li>\n",
    "<li>IP 주소, UserAgent 등 클라이언트 접속정보 출력하는 \"IP 확인 API\" 접근해서 정보를 추출하는 프로그램</li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#데이터 읽어들이기\n",
    "url=\"http://api.aoikujira.com/ip/ini\"\n",
    "res=request.urlopen(url)\n",
    "data=res.read()\n",
    "\n",
    "#바이너리를 문자열로 변환하기\n",
    "text=data.decode(\"utf-8\")\n",
    "print(text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h1 id=\"2.-BeautifulSoup\">2. BeautifulSoup<a class=\"anchor-link\" href=\"https://eclass2.ajou.ac.kr/bbcswebdav/pid-677816-dt-content-rid-9690516_1/courses/2020U00020032020084481/Crawling_exercise1.html#2.-BeautifulSoup\">¶</a></h1><ul>\n",
    "<li>스크레이핑(Scraping or Crawling)이란 웹 사이트에서 데이터를 추출하고, 원하는 정보를 추출하는 것을 의미</li>\n",
    "<li><code>BeautifulSoup</code>란 파이썬으로 스크레이핑할 때 사용되는 라이브러리로서 HTML/XML에서 정보를 추출할 수 있도록 도와줌. 그러나 다운로드 기능은 없음.</li>\n",
    "<li>파이썬 라이브러리는 pip 명령어를 이용해 설치 가능. Python Package Index(PyPI)에 있는 패키지 명령어를 한줄로 설치 가능<ul>\n",
    "<li>URL (<a href=\"http://pypi.python.org/pypi\">http://pypi.python.org/pypi</a>)</li>\n",
    "</ul>\n",
    "</li>\n",
    "</ul>\n",
    "<pre><code>pip install beautifulsoup4</code></pre>\n",
    "<ul>\n",
    "<li>예제 HTML</li>\n",
    "</ul>\n",
    "<div class=\"highlight\"><pre><span></span><span class=\"p\">&lt;</span><span class=\"nt\">html</span><span class=\"p\">&gt;&lt;</span><span class=\"nt\">body</span><span class=\"p\">&gt;</span>\n",
    "  <span class=\"p\">&lt;</span><span class=\"nt\">h1</span><span class=\"p\">&gt;</span>스크레이핑이란?<span class=\"p\">&lt;/</span><span class=\"nt\">h1</span><span class=\"p\">&gt;</span>\n",
    "  <span class=\"p\">&lt;</span><span class=\"nt\">p</span><span class=\"p\">&gt;</span>웹 페이지를 분석하는 것<span class=\"p\">&lt;/</span><span class=\"nt\">p</span><span class=\"p\">&gt;</span>\n",
    "  <span class=\"p\">&lt;</span><span class=\"nt\">p</span><span class=\"p\">&gt;</span>원하는 부분을 추출하는 것<span class=\"p\">&lt;/</span><span class=\"nt\">p</span><span class=\"p\">&gt;</span>\n",
    "<span class=\"p\">&lt;/</span><span class=\"nt\">body</span><span class=\"p\">&gt;&lt;/</span><span class=\"nt\">html</span><span class=\"p\">&gt;</span>\n",
    "</pre></div>\n",
    "<h3 id=\"패키지-import-및-예제-HTML\">패키지 import 및 예제 HTML<a class=\"anchor-link\" href=\"https://eclass2.ajou.ac.kr/bbcswebdav/pid-677816-dt-content-rid-9690516_1/courses/2020U00020032020084481/Crawling_exercise1.html#%ED%8C%A8%ED%82%A4%EC%A7%80-import-%EB%B0%8F-%EC%98%88%EC%A0%9C-HTML\">¶</a></h3>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "html = \"\"\"\n",
    "<html><body>\n",
    "  <h1>스크레이핑이란?</h1>\n",
    "  <p>웹 페이지를 분석하는 것</p>\n",
    "  <p>원하는 부분을 추출하는 것</p>\n",
    "</body></html>\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h2 id=\"2.1.-기본-사용\">2.1. 기본 사용<a class=\"anchor-link\" href=\"https://eclass2.ajou.ac.kr/bbcswebdav/pid-677816-dt-content-rid-9690516_1/courses/2020U00020032020084481/Crawling_exercise1.html#2.1.-%EA%B8%B0%EB%B3%B8-%EC%82%AC%EC%9A%A9\">¶</a></h2><ul>\n",
    "<li><p>다음은 Beautifulsoup를 이용하여 웹사이트로부터 HTML을 가져와 문자열로 만들어 이용하는 예제임</p>\n",
    "</li>\n",
    "<li><p>h1 태그를 접근하기 위해 html-body-h1 구조를 사용하여 soup.html.body.h1 이런식으로 이용하게 됨.</p>\n",
    "</li>\n",
    "<li>p 태그는 두개가 있어 soup.html.body.p 한 후 next_sibling을 두번 이용하여 다음 p를 추출. 한번만 하면 그 다음 공백이 추출됨.</li>\n",
    "<li>HTML 태그가 복잡한 경우 이런 방식으로 계속 진행하기는 적합하지 않음.</li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h3 id=\"2)-HTML-분석하기\">2) HTML 분석하기<a class=\"anchor-link\" href=\"https://eclass2.ajou.ac.kr/bbcswebdav/pid-677816-dt-content-rid-9690516_1/courses/2020U00020032020084481/Crawling_exercise1.html#2)-HTML-%EB%B6%84%EC%84%9D%ED%95%98%EA%B8%B0\">¶</a></h3>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h3 id=\"3)-원하는-부분-추출하기\">3) 원하는 부분 추출하기<a class=\"anchor-link\" href=\"https://eclass2.ajou.ac.kr/bbcswebdav/pid-677816-dt-content-rid-9690516_1/courses/2020U00020032020084481/Crawling_exercise1.html#3)-%EC%9B%90%ED%95%98%EB%8A%94-%EB%B6%80%EB%B6%84-%EC%B6%94%EC%B6%9C%ED%95%98%EA%B8%B0\">¶</a></h3>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "h1 = soup.html.body.h1\n",
    "p1 = soup.html.body.p\n",
    "p2 = p1.next_sibling.next_sibling\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h3 id=\"4)-요소의-글자-출력하기\">4) 요소의 글자 출력하기<a class=\"anchor-link\" href=\"https://eclass2.ajou.ac.kr/bbcswebdav/pid-677816-dt-content-rid-9690516_1/courses/2020U00020032020084481/Crawling_exercise1.html#4)-%EC%9A%94%EC%86%8C%EC%9D%98-%EA%B8%80%EC%9E%90-%EC%B6%9C%EB%A0%A5%ED%95%98%EA%B8%B0\">¶</a></h3>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(f\"h1 = {h1.string}\")\n",
    "print(f\"p  = {p1.string}\")\n",
    "print(f\"p  = {p2.string}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h2 id=\"2.2.-요소를-찾는-method\">2.2. 요소를 찾는 method<a class=\"anchor-link\" href=\"https://eclass2.ajou.ac.kr/bbcswebdav/pid-677816-dt-content-rid-9690516_1/courses/2020U00020032020084481/Crawling_exercise1.html#2.2.-%EC%9A%94%EC%86%8C%EB%A5%BC-%EC%B0%BE%EB%8A%94-method\">¶</a></h2><h3 id=\"단일-element-추출:-find()\">단일 element 추출: <code>find()</code><a class=\"anchor-link\" href=\"https://eclass2.ajou.ac.kr/bbcswebdav/pid-677816-dt-content-rid-9690516_1/courses/2020U00020032020084481/Crawling_exercise1.html#%EB%8B%A8%EC%9D%BC-element-%EC%B6%94%EC%B6%9C:-find()\">¶</a></h3><p>BeautifulSoup는 루트부터 하나하나 요소를 찾는 방법 말고도 find()라는 메소드를 제공함</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<ul>\n",
    "<li>1) <code>find()</code> 메서드로 원하는 부분 추출하기</li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "title = soup.find(\"h1\")\n",
    "body  = soup.find(\"p\")\n",
    "print(title)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<ul>\n",
    "<li>2) 텍스트 부분 출력하기</li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(f\"#title = {title.string}\" )\n",
    "print(f\"#body = {body.string}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h3 id=\"복수-elements-추출:-find_all()\">복수 elements 추출: <code>find_all()</code><a class=\"anchor-link\" href=\"https://eclass2.ajou.ac.kr/bbcswebdav/pid-677816-dt-content-rid-9690516_1/courses/2020U00020032020084481/Crawling_exercise1.html#%EB%B3%B5%EC%88%98-elements-%EC%B6%94%EC%B6%9C:-find_all()\">¶</a></h3><p>여러개의 태그를 한번에 추출하고자 할때 사용함. 다음의 예제에서는 여러개의 태그를 추출하는 법을 보여주고 있음</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "html = \"\"\"\n",
    "<html><body>\n",
    "  <ul>\n",
    "    <li><a href=\"http://www.naver.com\">naver</a></li>\n",
    "    <li><a href=\"http://www.daum.net\">daum</a></li>\n",
    "  </ul>\n",
    "</body></html>\n",
    "\"\"\"\n",
    "\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<ul>\n",
    "<li>1) <code>find_all()</code> 메서드로 추출하기</li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "links = soup.find_all(\"a\")\n",
    "print(links, len(links))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<ul>\n",
    "<li>2) 링크 목록 출력하기</li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for a in links:\n",
    "    href = a.attrs['href'] # href의 속성에 있는 속성값을 추출\n",
    "    text = a.string \n",
    "    print(text, \">\", href)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h1 id=\"3.-Css-Selector\">3. Css Selector<a class=\"anchor-link\" href=\"https://eclass2.ajou.ac.kr/bbcswebdav/pid-677816-dt-content-rid-9690516_1/courses/2020U00020032020084481/Crawling_exercise1.html#3.-Css-Selector\">¶</a></h1><blockquote><p>Css Selector란, 웹상의 요소에 css를 적용하기 위한 문법으로, 즉 요소를 선택하기 위한 패턴입니다.</p>\n",
    "<p>출처: <a href=\"https://www.w3schools.com/cssref/css_selectors.asp\">https://www.w3schools.com/cssref/css_selectors.asp</a></p>\n",
    "</blockquote>\n",
    "<p>앞서 간단하게 태그를 사용하여 데이터를 추출하는 방법에 대해서 살펴보았습니다.</p>\n",
    "<p>하지만 복잡하게 구조화된 웹 사이트에서 자신이 원하는 데이터를 가져오기 위해서는 Css Selector에 대한 이해가 필요합니다.</p>\n",
    "<table>\n",
    "<thead><tr>\n",
    "<th>서식</th>\n",
    "<th>설명</th>\n",
    "</tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "<tr>\n",
    "<td>*</td>\n",
    "<td>모든 요소를 선택</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>&lt;요소 이름&gt;</td>\n",
    "<td>요소 이름을 기반으로 선택</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>.&lt;클래스 이름&gt;</td>\n",
    "<td>클래스 이름을 기반으로 선택</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>#&lt;id 이름&gt;</td>\n",
    "<td>id 속성을 기반으로 선택</td>\n",
    "</tr>\n",
    "</tbody>\n",
    "</table>\n",
    "<h2 id=\"BeautifulSoup에서-Css-Selector-사용하기\"><code>BeautifulSoup</code>에서 Css Selector 사용하기<a class=\"anchor-link\" href=\"https://eclass2.ajou.ac.kr/bbcswebdav/pid-677816-dt-content-rid-9690516_1/courses/2020U00020032020084481/Crawling_exercise1.html#BeautifulSoup%EC%97%90%EC%84%9C-Css-Selector-%EC%82%AC%EC%9A%A9%ED%95%98%EA%B8%B0\">¶</a></h2><p><code>BeautifulSoup</code>에서는 Css Selector로 값을 가져올 수 있도록 <code>find</code>와는 다른 다음과 같은 메서드를 제공합니다.</p>\n",
    "<table>\n",
    "<thead><tr>\n",
    "<th>메서드</th>\n",
    "<th>설명</th>\n",
    "</tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "<tr>\n",
    "<td><code>soup.select_one(선택자)</code></td>\n",
    "<td>CSS 선택자로 요소 하나를 추출합니다.</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><code>soup.select(선택자)</code></td>\n",
    "<td>CSS 선택자로 요소 여러 개를 리스트를 추출합니다.</td>\n",
    "</tr>\n",
    "</tbody>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "html = \"\"\"\n",
    "<html><body>\n",
    "<div id=\"meigen\">\n",
    "  <h1>위키북스 도서</h1>\n",
    "  <ul class=\"items\">\n",
    "    <li>유니티 게임 이펙트 입문</li>\n",
    "    <li>스위프트로 시작하는 아이폰 앱 개발 교과서</li>\n",
    "    <li>모던 웹사이트 디자인의 정석</li>\n",
    "  </ul>\n",
    "</div>\n",
    "</body></html>\n",
    "\"\"\"\n",
    "\n",
    "# HTML 분석하기 \n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<ul>\n",
    "<li>필요한 부분을 CSS 쿼리로 추출하기</li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 타이틀 부분 추출하기 --- (※3)\n",
    "h1 = soup.select_one(\"div#meigen > h1\").string\n",
    "print(f\"h1 = {h1}\")\n",
    "\n",
    "# 목록 부분 추출하기 --- (※4)\n",
    "li_list = soup.select(\"div#meigen > ul.items > li\")\n",
    "for li in li_list:\n",
    "  print(f\"li = {li.string}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h1 id=\"4.-활용-예제\">4. 활용 예제<a class=\"anchor-link\" href=\"https://eclass2.ajou.ac.kr/bbcswebdav/pid-677816-dt-content-rid-9690516_1/courses/2020U00020032020084481/Crawling_exercise1.html#4.-%ED%99%9C%EC%9A%A9-%EC%98%88%EC%A0%9C\">¶</a></h1><p>앞서 배운  <code>urllib</code>과 <code>BeautifulSoup</code>를 조합하면, 웹스크레이핑 및 API 요청 작업을 쉽게 수행하실 수 있습니다.</p>\n",
    "<ol>\n",
    "<li>URL을 이용하여 웹으로부터 html을 읽어들임 (<code>urllib</code>)</li>\n",
    "<li>html 분석 및 원하는 데이터를 추출 (<code>BeautifulSoup</code>)</li>\n",
    "</ol>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib import request, parse\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h2 id=\"4.1.-네이버-금융---환율-정보\">4.1. 네이버 금융 - 환율 정보<a class=\"anchor-link\" href=\"https://eclass2.ajou.ac.kr/bbcswebdav/pid-677816-dt-content-rid-9690516_1/courses/2020U00020032020084481/Crawling_exercise1.html#4.1.-%EB%84%A4%EC%9D%B4%EB%B2%84-%EA%B8%88%EC%9C%B5---%ED%99%98%EC%9C%A8-%EC%A0%95%EB%B3%B4\">¶</a></h2><ul>\n",
    "<li>다양한 금융 정보가 공개돼 있는 \"네이버 금융\"에서 원/달러 환율 정보를 추출해보자!</li>\n",
    "<li>네이버 금융의 시장 지표 페이지 <a href=\"https://finance.naver.com/marketindex/\">https://finance.naver.com/marketindex/</a></li>\n",
    "<li>다음은 원/달러 환율 정보를 추출하는 프로그램임</li>\n",
    "</ul>\n",
    "<h3 id=\"1)-HTML-가져오기\">1) HTML 가져오기<a class=\"anchor-link\" href=\"https://eclass2.ajou.ac.kr/bbcswebdav/pid-677816-dt-content-rid-9690516_1/courses/2020U00020032020084481/Crawling_exercise1.html#1)-HTML-%EA%B0%80%EC%A0%B8%EC%98%A4%EA%B8%B0\">¶</a></h3>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "url = \"https://finance.naver.com/marketindex/\"\n",
    "res = request.urlopen(url)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h3 id=\"2)-HTML-분석하기\">2) HTML 분석하기<a class=\"anchor-link\" href=\"https://eclass2.ajou.ac.kr/bbcswebdav/pid-677816-dt-content-rid-9690516_1/courses/2020U00020032020084481/Crawling_exercise1.html#2)-HTML-%EB%B6%84%EC%84%9D%ED%95%98%EA%B8%B0\">¶</a></h3>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "soup = BeautifulSoup(res, \"html.parser\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h3 id=\"3)-원하는-데이터-추출하기\">3) 원하는 데이터 추출하기<a class=\"anchor-link\" href=\"https://eclass2.ajou.ac.kr/bbcswebdav/pid-677816-dt-content-rid-9690516_1/courses/2020U00020032020084481/Crawling_exercise1.html#3)-%EC%9B%90%ED%95%98%EB%8A%94-%EB%8D%B0%EC%9D%B4%ED%84%B0-%EC%B6%94%EC%B6%9C%ED%95%98%EA%B8%B0\">¶</a></h3>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "price = soup.select_one(\"div.head_info > span.value\").string\n",
    "print(\"usd/krw =\", price)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h2 id=\"4.2.-기상청-RSS\">4.2. 기상청 RSS<a class=\"anchor-link\" href=\"https://eclass2.ajou.ac.kr/bbcswebdav/pid-677816-dt-content-rid-9690516_1/courses/2020U00020032020084481/Crawling_exercise1.html#4.2.-%EA%B8%B0%EC%83%81%EC%B2%AD-RSS\">¶</a></h2><ul>\n",
    "<li>기상청 RSS에서 특정 내용을 추출하는 예제</li>\n",
    "<li>기상청 RSS에서 XML 데이터를 추출하고 XML 내용을 출력</li>\n",
    "<li>기상청의 RSS 서비스에 지역 번호를 지정하여 데이터 요청해보기 <a href=\"http://www.kma.go.kr/weather/forecast/mid-term-rss3.jsp\">http://www.kma.go.kr/weather/forecast/mid-term-rss3.jsp</a><ul>\n",
    "<li>참고: 기상청 RSS <a href=\"http://www.kma.go.kr/weather/lifenindustry/service_rss.jsp\">http://www.kma.go.kr/weather/lifenindustry/service_rss.jsp</a></li>\n",
    "</ul>\n",
    "</li>\n",
    "</ul>\n",
    "<table>\n",
    "<thead><tr>\n",
    "<th>매개변수</th>\n",
    "<th>의미</th>\n",
    "</tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "<tr>\n",
    "<td>stnid</td>\n",
    "<td>기상정보를 알고 싶은 지역을 지정</td>\n",
    "</tr>\n",
    "</tbody>\n",
    "</table>\n",
    "<ul>\n",
    "<li>지역번호는 다음과 같음</li>\n",
    "</ul>\n",
    "<table>\n",
    "<thead><tr>\n",
    "<th>지역</th>\n",
    "<th>지역번호</th>\n",
    "<th>지역</th>\n",
    "<th>지역번호</th>\n",
    "</tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "<tr>\n",
    "<td>전국</td>\n",
    "<td>108</td>\n",
    "<td>전라북도</td>\n",
    "<td>146</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>서울/경기도</td>\n",
    "<td>109</td>\n",
    "<td>전라남도</td>\n",
    "<td>156</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>강원도</td>\n",
    "<td>105</td>\n",
    "<td>경상북도</td>\n",
    "<td>143</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>충청북도</td>\n",
    "<td>131</td>\n",
    "<td>경상남도</td>\n",
    "<td>159</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>충청남도</td>\n",
    "<td>133</td>\n",
    "<td>제주특별자치도</td>\n",
    "<td>184</td>\n",
    "</tr>\n",
    "</tbody>\n",
    "</table>\n",
    "<ul>\n",
    "<li>파이썬으로 요청 전용 매개변수를 만들 때는 urllib.parse 모듈의 urlencode() 함수를 사용해 매개변수를 URL로 인코딩한다.</li>\n",
    "</ul>\n",
    "<h3 id=\"1)-HTML-가져오기\">1) HTML 가져오기<a class=\"anchor-link\" href=\"https://eclass2.ajou.ac.kr/bbcswebdav/pid-677816-dt-content-rid-9690516_1/courses/2020U00020032020084481/Crawling_exercise1.html#1)-HTML-%EA%B0%80%EC%A0%B8%EC%98%A4%EA%B8%B0\">¶</a></h3>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "url = \"http://www.kma.go.kr/weather/forecast/mid-term-rss3.jsp\"\n",
    "\n",
    "#매개변수를 URL로 인코딩한다.\n",
    "values = {\n",
    "    'stnId':'109'\n",
    "}\n",
    "\n",
    "params=parse.urlencode(values)\n",
    "url += \"?\"+params # URL에 매개변수 추가\n",
    "print(\"url=\", url)\n",
    "\n",
    "res = request.urlopen(url)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h3 id=\"2)-HTML-분석하기\">2) HTML 분석하기<a class=\"anchor-link\" href=\"https://eclass2.ajou.ac.kr/bbcswebdav/pid-677816-dt-content-rid-9690516_1/courses/2020U00020032020084481/Crawling_exercise1.html#2)-HTML-%EB%B6%84%EC%84%9D%ED%95%98%EA%B8%B0\">¶</a></h3>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "soup = BeautifulSoup(res, \"html.parser\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h3 id=\"3)-원하는-데이터-추출하기\">3) 원하는 데이터 추출하기<a class=\"anchor-link\" href=\"https://eclass2.ajou.ac.kr/bbcswebdav/pid-677816-dt-content-rid-9690516_1/courses/2020U00020032020084481/Crawling_exercise1.html#3)-%EC%9B%90%ED%95%98%EB%8A%94-%EB%8D%B0%EC%9D%B4%ED%84%B0-%EC%B6%94%EC%B6%9C%ED%95%98%EA%B8%B0\">¶</a></h3>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "header = soup.find(\"header\")\n",
    "\n",
    "title = header.find(\"title\").text\n",
    "wf = header.find(\"wf\").text\n",
    "\n",
    "print(title)\n",
    "print(wf)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<ul>\n",
    "<li>css selector 기반</li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "title = soup.select_one(\"header > title\").text\n",
    "wf = header.select_one(\"header wf\").text\n",
    "\n",
    "print(title)\n",
    "print(wf)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h2 id=\"4.3.-윤동주-작가의-작품-목록\">4.3. 윤동주 작가의 작품 목록<a class=\"anchor-link\" href=\"https://eclass2.ajou.ac.kr/bbcswebdav/pid-677816-dt-content-rid-9690516_1/courses/2020U00020032020084481/Crawling_exercise1.html#4.3.-%EC%9C%A4%EB%8F%99%EC%A3%BC-%EC%9E%91%EA%B0%80%EC%9D%98-%EC%9E%91%ED%92%88-%EB%AA%A9%EB%A1%9D\">¶</a></h2><ul>\n",
    "<li>위키문헌 (<a href=\"https://ko.wikisource.org/wiki\">https://ko.wikisource.org/wiki</a>) 에 공개되어 있는 윤동주의 작품목록을 가져오기</li>\n",
    "<li>윤동주 위키 (<a href=\"https://ko.wikisource.org/wiki/%EC%A0%80%EC%9E%90:%EC%9C%A4%EB%8F%99%EC%A3%BC\">https://ko.wikisource.org/wiki/%EC%A0%80%EC%9E%90:%EC%9C%A4%EB%8F%99%EC%A3%BC</a>)</li>\n",
    "<li>하늘과 바람과 시 부분을 선택한 후 오른쪽 마우스 이용해 copy selector로 카피하면 다음의 CSS 선택자가 카피됨<ul>\n",
    "<li><code>#mw-content-text &gt; div &gt; ul:nth-child(6) &gt; li &gt; b &gt; a</code></li>\n",
    "</ul>\n",
    "</li>\n",
    "<li>nth-child(n) 은 n 번째 요소를 의미 즉 6번째 요소를 의미, <code>#mw-content-text</code> 내부에 있는 url 태그는 모두 작품과 관련된 태그. 따라서 따로 구분할 필요는 없으며 생략해도 됨. BeautifulSoup는 nth-child 지원하지 않음<ul>\n",
    "<li>Recall PR7 Problem1</li>\n",
    "</ul>\n",
    "</li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 뒤의 인코딩 부분은 \"저자:윤동주\"라는 의미입니다.\n",
    "# 따로 입력하지 말고 위키 문헌 홈페이지에 들어간 뒤에 주소를 복사해서 사용하세요.\n",
    "\n",
    "url = \"https://ko.wikisource.org/wiki/%EC%A0%80%EC%9E%90:%EC%9C%A4%EB%8F%99%EC%A3%BC\"\n",
    "res = request.urlopen(url)\n",
    "soup = BeautifulSoup(res, \"html.parser\")\n",
    "\n",
    "# #mw-content-text 바로 아래에 있는 \n",
    "# ul 태그 바로 아래에 있는\n",
    "# li 태그 아래에 있는\n",
    "# a 태그를 모두 선택합니다.\n",
    "a_list = soup.select(\"#mw-content-text   ul > li  a\")\n",
    "for a in a_list:\n",
    "    name = a.string\n",
    "    print(f\"- {name}\", )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h1 id=\"일반문제\">일반문제<a class=\"anchor-link\" href=\"https://eclass2.ajou.ac.kr/bbcswebdav/pid-677816-dt-content-rid-9690516_1/courses/2020U00020032020084481/Crawling_exercise1.html#%EC%9D%BC%EB%B0%98%EB%AC%B8%EC%A0%9C\">¶</a></h1><hr/>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib import request\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h2 id=\"1.-네이버-뉴스-헤드라인\">1. 네이버 뉴스 헤드라인<a class=\"anchor-link\" href=\"https://eclass2.ajou.ac.kr/bbcswebdav/pid-677816-dt-content-rid-9690516_1/courses/2020U00020032020084481/Crawling_exercise1.html#1.-%EB%84%A4%EC%9D%B4%EB%B2%84-%EB%89%B4%EC%8A%A4-%ED%97%A4%EB%93%9C%EB%9D%BC%EC%9D%B8\">¶</a></h2><p>배운 내용을 바탕으로 네이버 뉴스(<a href=\"https://news.naver.com/)%EC%97%90%EC%84%9C\">https://news.naver.com/)에서</a> 헤드라인 뉴스의 제목을 추출해보고자 합니다.</p>\n",
    "<blockquote><p><strong><em>Q</em></strong>: 다음의 코드에 css selector를 추가하여 최신 기사의 헤드라인을 스크레이핑하는 코드를 완성하시오.</p>\n",
    "</blockquote>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "url = \"https://news.naver.com/\"\n",
    "\n",
    "res = request.urlopen(url)\n",
    "soup = BeautifulSoup(res, \"html.parser\")\n",
    "\n",
    "selector = \"#today_main_news > div.hdline_news > ul > li > div.hdline_article_tit > a\"\n",
    "\n",
    "for a in soup.select(selector):\n",
    "    title = a.text\n",
    "    print(title)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h2 id=\"2.-시민의-소리-게시판\">2. 시민의 소리 게시판<a class=\"anchor-link\" href=\"https://eclass2.ajou.ac.kr/bbcswebdav/pid-677816-dt-content-rid-9690516_1/courses/2020U00020032020084481/Crawling_exercise1.html#2.-%EC%8B%9C%EB%AF%BC%EC%9D%98-%EC%86%8C%EB%A6%AC-%EA%B2%8C%EC%8B%9C%ED%8C%90\">¶</a></h2><p>다음은 서울시 대공원의 시민의 소리 게시판 입니다.</p>\n",
    "<p><a href=\"https://www.sisul.or.kr/open_content/childrenpark/qna/qnaMsgList.do?pgno=1\">https://www.sisul.or.kr/open_content/childrenpark/qna/qnaMsgList.do?pgno=1</a></p>\n",
    "<p>해당 페이지에 나타난 게시글들의 제목을 수집하고자 합니다.</p>\n",
    "<blockquote><p><strong><em>Q</em></strong>: 다음의 코드에 css selector를 추가하여 해당 페이지에서 게시글의 제목을 스크레이핑하는 코드를 완성하시오. 또한 과제 제출시 하단의 <strong>추가 내용</strong>을 참고하여 수집한 데이터를 csv 형태로 저장하여 해당 csv 파일도 함께 제출하시오.</p>\n",
    "</blockquote>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "url_head = \"https://www.sisul.or.kr\"\n",
    "\n",
    "url_board = url_head + \"/open_content/childrenpark/qna/qnaMsgList.do?pgno=1\"\n",
    "\n",
    "\n",
    "\n",
    "res = request.urlopen(url_board)\n",
    "soup = BeautifulSoup(res, \"html.parser\")\n",
    "\n",
    "# selector = \"#detail_con > div.generalboard > table > tbody > tr > td.left.title > a\"\n",
    "selector = \"#detail_con > div.generalboard > table > tbody > tr > td.left.title > a\"\n",
    "titles = []\n",
    "links = []\n",
    "for a in soup.select(selector):\n",
    "    titles.append(a.text)\n",
    "    links.append(url_head + a.attrs[\"href\"])\n",
    "    \n",
    "print(titles, links)\n",
    "\n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h3 id=\"추가-내용\">추가 내용<a class=\"anchor-link\" href=\"https://eclass2.ajou.ac.kr/bbcswebdav/pid-677816-dt-content-rid-9690516_1/courses/2020U00020032020084481/Crawling_exercise1.html#%EC%B6%94%EA%B0%80-%EB%82%B4%EC%9A%A9\">¶</a></h3><p>수집된 자료를 데이터프레임으로 만들어 csv로 저장하는 것이 일반적입니다.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "board_df = pd.DataFrame({\"title\": titles, \"link\": links})\n",
    "board_df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "board_df.to_csv(\"board.csv\", index=False)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
